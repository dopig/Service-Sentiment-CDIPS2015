{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads in vectorizer and logistic regression joblib files (scikitlearn said it's better than pickle for large things) trained on whole, extreme reviews (with 100+ reviews) from the academic dataset.\n",
    "\n",
    "It uses these trained algorithms to score each service sentence and append these as a new column in Francine's file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#You can read the file this produces with the following:\n",
    "#pd.read_csv(\"review_sentences_final_academic_service_words_scored.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here load pickle (joblib) files trained on Extreme Reviews file with balanced # of good and bad reviews (thursday 2015/07/30 edition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc = joblib.load('Yelp2015/pickle/vectorizer_thursday.pkl')\n",
    "lr = joblib.load('Yelp2015/pickle/logreg_thursday.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First just confirm can load and run the pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i don t care what other people say top dog is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top dog saved the day again with hot wieners a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when i m in the area i usually drop in a for q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean  score\n",
       "0  i don t care what other people say top dog is ...      1\n",
       "1  top dog saved the day again with hot wieners a...      1\n",
       "2  when i m in the area i usually drop in a for q...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme = pd.read_csv(\"Yelp2015/yelp_academic_reviews_extreme_partial.csv\", index_col = 0)\n",
    "extreme.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorize and do regression on clean whole reviews.\n",
    "X = extreme.clean\n",
    "Xvec = vc.transform(X).toarray()\n",
    "y_pred = lr.predict(Xvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989644561916\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(extreme.score, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above shows I can load the predictor and run it on the set it was trained on and recapitulate the scores.  NOW LETS SEE HOW IT DOES WITH SENTENCES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113278, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qHmamQPCAKkia9X0uryA8g</td>\n",
       "      <td>2012-06-15</td>\n",
       "      <td>hIrFN-5jhCo04AvhsNtimg</td>\n",
       "      <td>5</td>\n",
       "      <td>You order in 3 seconds and you're out in 5 min...</td>\n",
       "      <td>review</td>\n",
       "      <td>P-xcy872BvGcClkNpNlPqQ</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qHmamQPCAKkia9X0uryA8g</td>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>C3XPzVWPoqK_FpgItJFtjg</td>\n",
       "      <td>4</td>\n",
       "      <td>The guy behind the counter was very friendly a...</td>\n",
       "      <td>review</td>\n",
       "      <td>S6BXOUedzPH58K0rYY1loQ</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  qHmamQPCAKkia9X0uryA8g  2012-06-15  hIrFN-5jhCo04AvhsNtimg      5   \n",
       "1  qHmamQPCAKkia9X0uryA8g  2010-12-10  C3XPzVWPoqK_FpgItJFtjg      4   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  You order in 3 seconds and you're out in 5 min...  review   \n",
       "1  The guy behind the counter was very friendly a...  review   \n",
       "\n",
       "                  user_id                                    votes  \n",
       "0  P-xcy872BvGcClkNpNlPqQ  {u'funny': 0, u'useful': 1, u'cool': 1}  \n",
       "1  S6BXOUedzPH58K0rYY1loQ  {u'funny': 0, u'useful': 0, u'cool': 0}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try to evaluate sentences from Francine's service words sentences file from today.\n",
    "df = pd.read_csv(\"Downloads/review_sentences_final_academic_service_words_NEW.csv\", index_col=0)\n",
    "df.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "print df.shape\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean the sentences\n",
    "def cleantext(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text).lower()  #This removes everything that isn't a letter\n",
    "    return re.sub( '\\s+', ' ', text).strip()  #This removes excess spaces\n",
    "\n",
    "clean = df.text.apply(cleantext).values\n",
    "df['clean'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You order in 3 seconds and you're out in 5 minutes!\n",
      "you order in seconds and you re out in minutes\n"
     ]
    }
   ],
   "source": [
    "print df.iloc[0,4]\n",
    "print df.iloc[0,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorize sentences\n",
    "sentencevec = vc.transform(df.clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do logistic regression\n",
    "senpred = lr.predict(sentencevec)\n",
    "senproba = lr.predict_proba(sentencevec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba_bad, proba_good = zip(*senproba)\n",
    "df['senpred'] = senpred\n",
    "df['proba_bad'] = proba_bad\n",
    "df['proba_good'] = proba_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0923b91f0f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113278\n",
      "12727\n",
      "20827\n"
     ]
    }
   ],
   "source": [
    "print len(df)\n",
    "print len(df[df.proba_good>0.9]) \n",
    "print len(df[df.proba_bad>0.9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save to file\n",
    "df.to_csv(\"review_sentences_final_academic_service_words_NEW_sen_proba.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 0.49654368  0.50345632] time\n",
      "0 [ 0.6615704  0.3384296] minutes\n",
      "0 [ 0.70393383  0.29606617] seconds minutes\n",
      "0 [ 0.5213172  0.4786828] three seconds\n",
      "1 [ 0.45095211  0.54904789] ugly\n",
      "1 [ 0.48727826  0.51272174] flkslkfdj\n",
      "1 [ 0.46116682  0.53883318] unicorn\n",
      "1 [ 0.15472862  0.84527138] amazing minutes\n"
     ]
    }
   ],
   "source": [
    "#Now let's test random phrases for fun.\n",
    "\n",
    "test = [\"time\", \"minutes\", \"seconds minutes\", \"three seconds\", \"ugly\", \"flkslkfdj\", \"unicorn\", \"amazing minutes\"]\n",
    "testvec = vc.transform(test)\n",
    "testpred = lr.predict(testvec)\n",
    "testprob = lr.predict_proba(testvec)\n",
    "for i in range(len(test)):\n",
    "    print testpred[i], testprob[i], test[i]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
